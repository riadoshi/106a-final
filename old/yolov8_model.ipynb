{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the YOLOv8 Nano model\n",
    "model = YOLO(\"yolov8n.pt\") \n",
    "\n",
    "# Define a filter for the target objects\n",
    "TARGET_OBJECTS = [\"soda can\", \"water bottle\", \"plastic cup\", \"milk container\"]\n",
    "\n",
    "def detect_objects(image: np.ndarray):\n",
    "    \"\"\"\n",
    "    Perform inference on a numpy array image using YOLO.\n",
    "    Args:\n",
    "        image (np.ndarray): Input image as a numpy array (BGR format).\n",
    "    Returns:\n",
    "        list: List of detections with labels, bounding boxes, and confidences.\n",
    "    \"\"\"\n",
    "    # Convert numpy array (BGR) to RGB format as required by YOLO\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform inference\n",
    "    results = model(rgb_image)\n",
    "\n",
    "    # Parse results\n",
    "    print(results)\n",
    "    detections = results.xyxy[0].cpu().numpy()  # Bounding box format: [x1, y1, x2, y2, confidence, class]\n",
    "    labels = results.names\n",
    "\n",
    "    print(labels)\n",
    "\n",
    "    output = []\n",
    "    for detection in detections:\n",
    "        x1, y1, x2, y2, confidence, cls_id = detection\n",
    "        label = labels[int(cls_id)]\n",
    "        # if label in TARGET_OBJECTS:\n",
    "        output.append({\n",
    "            \"label\": label,\n",
    "            \"bounding_box\": [int(x1), int(y1), int(x2), int(y2)],\n",
    "            \"confidence\": float(confidence)\n",
    "        })\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x608 1 stop sign, 1 cup, 1 dining table, 12.1ms\n",
      "Speed: 7.4ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[255, 255, 255],\n",
      "        [132, 141, 148],\n",
      "        [132, 141, 148],\n",
      "        ...,\n",
      "        [186, 237, 190],\n",
      "        [188, 239, 189],\n",
      "        [189, 240, 189]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [131, 141, 148],\n",
      "        [131, 141, 148],\n",
      "        ...,\n",
      "        [183, 234, 185],\n",
      "        [185, 236, 184],\n",
      "        [186, 237, 184]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [131, 141, 148],\n",
      "        [131, 141, 148],\n",
      "        ...,\n",
      "        [180, 232, 181],\n",
      "        [182, 234, 179],\n",
      "        [184, 235, 178]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [154, 115,  88],\n",
      "        [153, 115,  88],\n",
      "        ...,\n",
      "        [166, 160, 146],\n",
      "        [169, 163, 149],\n",
      "        [171, 165, 153]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [154, 113,  86],\n",
      "        [154, 113,  85],\n",
      "        ...,\n",
      "        [167, 160, 146],\n",
      "        [169, 162, 148],\n",
      "        [171, 164, 152]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [156, 115,  85],\n",
      "        [155, 114,  84],\n",
      "        ...,\n",
      "        [169, 162, 148],\n",
      "        [170, 163, 149],\n",
      "        [171, 163, 151]]], dtype=uint8)\n",
      "orig_shape: (1262, 1184)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/detect/predict'\n",
      "speed: {'preprocess': 7.351398468017578, 'inference': 12.143373489379883, 'postprocess': 1.4698505401611328}]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m results \u001b[38;5;241m=\u001b[39m detect_objects(image)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDetected \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m with confidence \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfidence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.2f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m at \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbounding_box\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Load a sample image as a numpy array given a path\n",
    "image_path = '/home/riadoshi/106a/test_images/can_R.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform detection\n",
    "results = detect_objects(image)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(f\"Detected {result['label']} with confidence {result['confidence']:.2f} at {result['bounding_box']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
